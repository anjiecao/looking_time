block_length,
dev_positions)))
) %>%
mutate(beta = map(.x = sequence,
.f = get_beta_count),
probability = map(.x = beta,
.f = get_probability),
surprise = map2(.x = probability,
.y = sequence,
.f = get_surprise),
learning_progress = map(
.x = probability,
.f = get_learning_progress
)) %>%
unnest(sequence, surprise, learning_progress) %>%
unnest(learning_progress) %>%
# figure out the corresponding trial number
group_by(subject, block_number) %>%
mutate(trial_number = row_number())
d_rt <- d %>%
select(subject, block_number, trial_number, rt, item_type, trial_type, trial_complexity) %>%
mutate(rt = rt + 500) %>%  # add the baseline back
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
#rename(real_trial_number = trial_number) %>%
select(temp_id, rt, item_type, trial_type, trial_complexity)
d_exp_sim <- d_exp_sim %>%
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
left_join(d_rt, by = "temp_id")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "surprise") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("surprise") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "learning_progress") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
theme(legend.position = "bottom") +
ylab("learning_progress") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "rt") %>%
ggplot(
aes(x=trial_number, y=log(measure_value), colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("Log looking time (ms)") +
xlab("Trial Number")  +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
group_by(trial_number, item_type, trial_complexity) %>%
summarise(
mean_rt = mean(log(rt)),
mean_kl = mean(learning_progress),
mean_surprise = mean(surprise)
) %>%
ggplot(aes(x= mean_kl, y = mean_rt)) +
geom_point() +
geom_smooth(method = "lm") +
ylab("log looking time (ms)") +
xlab("KL divergence") +
theme_classic() +
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"))
#technically we only need one sequence if we want to vary prior
df_sequence <- generate_sequence_with_parameter(
d_experiment_parameter,
200,
100,
50,
0.2,
0.6)
df_sequence
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
source(here("adult_modeling/scripts/archive/00_generate_stimuli.R"))
source(here("adult_modeling/scripts/archive/01_get_learning_measure.R"))
source(here("adult_modeling/scripts/archive/02_get_experiment_parameter.R"))
d <- read_csv(here("adult_modeling/data/processed_RTdata.csv"))
# translate the experiment sequence into model-compatible structure
d_experiment_parameter <- get_experiment_parameter(d)
d_exp_sim <- d_experiment_parameter %>%
# the block length doesn't match
mutate(
sequence = pmap(d_experiment_parameter %>% select(-c(subject, block_number)), .f = ~with(list(...),
get_block_sequence(complexity, similarity,
20,
5, 10,
0.2, 0.8,
block_length,
dev_positions)))
) %>%
mutate(beta = map(.x = sequence,
.f = get_beta_count),
probability = map(.x = beta,
.f = get_probability),
surprise = map2(.x = probability,
.y = sequence,
.f = get_surprise),
learning_progress = map(
.x = probability,
.f = get_learning_progress
)) %>%
unnest(sequence, surprise, learning_progress) %>%
unnest(learning_progress) %>%
# figure out the corresponding trial number
group_by(subject, block_number) %>%
mutate(trial_number = row_number())
d_rt <- d %>%
select(subject, block_number, trial_number, rt, item_type, trial_type, trial_complexity) %>%
mutate(rt = rt + 500) %>%  # add the baseline back
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
#rename(real_trial_number = trial_number) %>%
select(temp_id, rt, item_type, trial_type, trial_complexity)
d_exp_sim <- d_exp_sim %>%
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
left_join(d_rt, by = "temp_id")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "surprise") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("surprise") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "learning_progress") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
theme(legend.position = "bottom") +
ylab("learning_progress") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "rt") %>%
ggplot(
aes(x=trial_number, y=log(measure_value), colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("Log looking time (ms)") +
xlab("Trial Number")  +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
group_by(trial_number, item_type, trial_complexity) %>%
summarise(
mean_rt = mean(log(rt)),
mean_kl = mean(learning_progress),
mean_surprise = mean(surprise)
) %>%
ggplot(aes(x= mean_kl, y = mean_rt)) +
geom_point() +
geom_smooth(method = "lm") +
ylab("log looking time (ms)") +
xlab("KL divergence") +
theme_classic() +
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"))
d_exp_sim %>%
group_by(trial_number, item_type, trial_complexity) %>%
summarise(
mean_rt = mean(log(rt)),
mean_kl = mean(learning_progress),
mean_surprise = mean(surprise)
) %>%
ggplot(aes(x= mean_surprise, y = mean_rt)) +
geom_point() +
geom_smooth(method = "lm") +
ylab("log looking time (ms)") +
xlab("Surprise") +
theme_classic() +
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"))
d_cor <- d_exp_sim %>%
select(subject, block_number, trial_number,
trial_type, trial_complexity, item_type,
surprise, learning_progress, rt) %>%
mutate(log_rt = log(rt))
d_cor_summary <- d_cor %>%
ungroup() %>%
group_by(item_type,
trial_complexity,
trial_number) %>%
summarise(
mean_suprirse = mean(surprise),
mean_lp = mean(learning_progress),
mean_log_rt = mean(log_rt))
d_exp_sim <- d_experiment_parameter %>%
# the block length doesn't match
mutate(
sequence = pmap(d_experiment_parameter %>% select(-c(subject, block_number)), .f = ~with(list(...),
get_block_sequence(complexity, similarity,
200,
50, 100,
0.2, 0.6,
block_length,
dev_positions)))
) %>%
mutate(beta = map(.x = sequence,
.f = get_beta_count),
probability = map(.x = beta,
.f = get_probability),
surprise = map2(.x = probability,
.y = sequence,
.f = get_surprise),
learning_progress = map(
.x = probability,
.f = get_learning_progress
)) %>%
unnest(sequence, surprise, learning_progress) %>%
unnest(learning_progress) %>%
# figure out the corresponding trial number
group_by(subject, block_number) %>%
mutate(trial_number = row_number())
d_rt <- d %>%
select(subject, block_number, trial_number, rt, item_type, trial_type, trial_complexity) %>%
mutate(rt = rt + 500) %>%  # add the baseline back
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
#rename(real_trial_number = trial_number) %>%
select(temp_id, rt, item_type, trial_type, trial_complexity)
d_exp_sim <- d_exp_sim %>%
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
left_join(d_rt, by = "temp_id")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "surprise") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("surprise") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "learning_progress") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
theme(legend.position = "bottom") +
ylab("learning_progress") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "rt") %>%
ggplot(
aes(x=trial_number, y=log(measure_value), colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("Log looking time (ms)") +
xlab("Trial Number")  +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
# translate the experiment sequence into model-compatible structure
d_experiment_parameter <- get_experiment_parameter(d)
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
source(here("adult_modeling/scripts/archive/00_generate_stimuli.R"))
source(here("adult_modeling/scripts/archive/01_get_learning_measure.R"))
source(here("adult_modeling/scripts/archive/02_get_experiment_parameter.R"))
d <- read_csv(here("adult_modeling/data/processed_RTdata.csv"))
d_exp_sim <- d_experiment_parameter %>%
# the block length doesn't match
mutate(
sequence = pmap(d_experiment_parameter %>% select(-c(subject, block_number)), .f = ~with(list(...),
get_block_sequence(complexity, similarity,
200,
50, 100,
0.2, 0.6,
block_length,
dev_positions)))
) %>%
mutate(beta = map(.x = sequence,
.f = get_beta_count),
probability = map(.x = beta,
.f = get_probability),
surprise = map2(.x = probability,
.y = sequence,
.f = get_surprise),
learning_progress = map(
.x = probability,
.f = get_learning_progress
)) %>%
unnest(sequence, surprise, learning_progress) %>%
unnest(learning_progress) %>%
# figure out the corresponding trial number
group_by(subject, block_number) %>%
mutate(trial_number = row_number())
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
source(here("adult_modeling/scripts/archive/00_generate_stimuli.R"))
source(here("adult_modeling/scripts/archive/01_get_learning_measure.R"))
source(here("adult_modeling/scripts/archive/02_get_experiment_parameter.R"))
d <- read_csv(here("adult_modeling/data/processed_RTdata.csv"))
# translate the experiment sequence into model-compatible structure
d_experiment_parameter <- get_experiment_parameter(d)
d_exp_sim <- d_experiment_parameter %>%
# the block length doesn't match
mutate(
sequence = pmap(d_experiment_parameter %>% select(-c(subject, block_number)), .f = ~with(list(...),
get_block_sequence(complexity, similarity,
200,
50, 100,
0.2, 0.6,
block_length,
dev_positions)))
) %>%
mutate(beta = map(.x = sequence,
.f = get_beta_count),
probability = map(.x = beta,
.f = get_probability),
surprise = map2(.x = probability,
.y = sequence,
.f = get_surprise),
learning_progress = map(
.x = probability,
.f = get_learning_progress
)) %>%
unnest(sequence, surprise, learning_progress) %>%
unnest(learning_progress) %>%
# figure out the corresponding trial number
group_by(subject, block_number) %>%
mutate(trial_number = row_number())
d_rt <- d %>%
select(subject, block_number, trial_number, rt, item_type, trial_type, trial_complexity) %>%
mutate(rt = rt + 500) %>%  # add the baseline back
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
#rename(real_trial_number = trial_number) %>%
select(temp_id, rt, item_type, trial_type, trial_complexity)
d_exp_sim <- d_exp_sim %>%
mutate(temp_id = paste(subject, block_number, trial_number)) %>%
left_join(d_rt, by = "temp_id")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "surprise") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("surprise") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "learning_progress") %>%
ggplot(
aes(x=trial_number, y=measure_value, colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
theme(legend.position = "bottom") +
ylab("learning_progress") +
xlab("Trial Number") +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
d_exp_sim %>%
pivot_longer(cols = c(surprise, learning_progress, rt),
names_to = "measure_type",
values_to = "measure_value") %>%
filter(measure_type == "rt") %>%
ggplot(
aes(x=trial_number, y=log(measure_value), colour=item_type)) +
stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) +
geom_smooth(method = "lm",
formula = y ~ I(exp(1)**(-x)), se = FALSE) +
facet_grid(~trial_complexity) +
langcog::scale_color_solarized(name = "Item Type") +
ylab("Log looking time (ms)") +
xlab("Trial Number")  +
theme_classic()+
theme(
axis.text=element_text(size=12),
axis.title=element_text(size=14,face="bold"),
legend.position = "bottom")
saveRDS(d_exp_sim, file = here("connecting_data_res.RDS"))
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
source(here("adult_modeling/scripts/archive/00_generate_stimuli.R"))
source(here("adult_modeling/scripts/archive/01_get_learning_measure.R"))
source(here("adult_modeling/scripts/archive/02_get_experiment_parameter.R"))
d <- read_csv(here("adult_modeling/data/processed_RTdata.csv"))
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
source(here("adult_modeling/scripts/archive/00_generate_stimuli.R"))
source(here("adult_modeling/scripts/archive/01_get_learning_measure.R"))
source(here("adult_modeling/scripts/archive/02_get_experiment_parameter.R"))
d <- read_csv(here("adult_modeling/data/processed_RTdata.csv"))
# translate the experiment sequence into model-compatible structure
d_experiment_parameter <- get_experiment_parameter(d)
View(d_experiment_parameter)
saveRDS(d_experiment_parameter, file = here("experiment_parameter.RDS"))
