---
title: "01_preprocessing.R"
author: "anjie"
date: "9/18/2020"
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(here)
library(jsonlite)
library(kableExtra)
library(DT)
library(dict)
library(ggforce)
library(ggimage)
library(stringr)
library(showtext)# for displaying chinese characters


source(here("preprocessing/exclude/exclude_task.R"))
source(here("preprocessing/exclude/exclude_complete.R"))
source(here("preprocessing/exclude/exclude_demog.R"))
source(here("preprocessing/extract/extract_demog.R"))
source(here("preprocessing/extract/extract_HIT.R"))
source(here("preprocessing/extract/extract_humanCheck.R"))

source(here("preprocessing/task/ebbinghaus.R"))
source(here("preprocessing/task/RMTS.R"))
source(here("preprocessing/task/self_inflation.R"))
source(here("preprocessing/task/horizon_sticker.R"))
source(here("preprocessing/task/conformity_preference.R"))
source(here("preprocessing/task/raven.R"))
source(here("preprocessing/task/free_description.R"))
source(here("preprocessing/task/causal_attribution.R"))
```



```{r setup_paths}
US_PATH <- "data/1_raw_data/US/"
CN_PATH <- "data/1_raw_data/CN/"

MERGED_DATA_PATH <- here("data/2_merged/merged_all.csv")
MERGED_DEMOGS_PATH <- here("data/2_merged/merged_demogs.csv")


US_TBA_FD_PATH <- here("data/to_be_annotated/US/us_tba_fd.csv")
US_TBA_CA_PATH <- here("data/to_be_annotated/US/us_tba_ca.csv")
US_SYMS_LABEL_PATH <- here("data/to_be_annotated/US/us_syms_label.csv")
#funnel debriefing and sanity check 
US_HUMANREAD_PATH <- here("data/to_be_annotated/US/us_hr.csv")
US_CIRCLE_DIR <- here("data/to_be_annotated/US/Circle/")
US_CIRCLE_CODING_PATH <- here("data/to_be_annotated/US/Circle/us_tba_si.csv")


CN_TBA_FD_PATH <- here("data/to_be_annotated/CN/cn_tba_fd.csv")
CN_TBA_CA_PATH <- here("data/to_be_annotated/CN/cn_tba_ca.csv")
CN_SYMS_LABEL_PATH <- here("data/to_be_annotated/CN/cn_syms_label.csv")
CN_HUMANREAD_PATH <- here("data/to_be_annotated/CN/cn_hr.csv")
CN_CIRCLE_DIR <- here("data/to_be_annotated/CN/Circle/")
CN_CIRCLE_CODING_PATH <- here("data/to_be_annotated/CN/Circle/cn_tba_si.csv")



# task-based exclusion and completion based exclusion
TRIMMED_DATA_PATH <- here("data/3_trimmed/trimmed_all.csv")
TRIMMED_DEMOGS_PATH <- here("data/3_trimmed/trimmed_demogs.csv")



# tidy data 
PROCESSED_MAIN_PATH <- here("data/4_processed/tidy_main.csv")

```

# Intro 
This script will read in the raw data from servers and generate a series of files in `data` folder 
The folders are organized as following: 

- 1_raw_data (does not live on github)
  - US: *.csv, raw data from servers
  - CN: *.csv, raw data from servers 

- 2_merged
  - `merged_data.csv`: aggregated data from both `1_raw_data/US` and `1_raw_data/CN`, untrimmed / unprocessed 
  - `merged_demogs.csv`: aggregated demographic information from both `1_raw_data/US` and `1_raw_data/CN`, untrimmed / unprocessed 

- 3_trimmed 
  - `trimmed_data.csv`: generated from `merged_data.csv` and `merged_demogs.csv`using task-based exclusion & demographic-based exclusion  
  - `trimmed_demogs.csv`: generated from trimmed_data.csv

- 4_processed 
  - `tidy_main.csv`: main analysis table processed from trimme_data.dsv
  - ... [may have task-specific exploratory analysis]

- to_be_annotated (data that needs human to check)
  - `US`
    - `us_tba_ca.csv`: causal attribution answer to be annotated
    - `us_tba_fd.csv`: free description answer to be annotated 
    - `us_hr.csv`: funnel debriefing answer and general feedback
  - `CN`
    - `cn_tba_ca.csv`: causal attribution answer to be annotated
    - `cn_tba_fd.csv`: free description answer to be annotated 
    - `cn_hr.csv`: funnel debriefing answer and general feedback

# Read in raw data 
The current script saves data for users who did not finish the experiment, including those who did not finish the pre-experiment instruction session. As a result, there are going to be a non-trivial number of csv files that contain non-usable data. In these non-usable* csv file, the number of columns do not match with other participants, causing the `map_df`read in function won't work. Therefore the first step is to examine and exclude the non-usable csv files. 

*note:  we distinguish between participants who proceeded long enough into the experiment and quit with those who did not really start the experiment. With our preregistration criteria, the former might be included in the final analysis, if we have more than 20% exclusion rate. On the contrary, the later will be excluded in this first step. 

First, we can examine how many csv files are from usable data. 
```{r message=FALSE}
us_files <- str_c(US_PATH, dir(here(US_PATH), "*.csv"))
cn_files <- str_c(CN_PATH, dir(here(CN_PATH), "*.csv"))


us_data_RAW <- map_df(us_files, function(file) {
  d <- read_csv(file) %>% 
    count() %>% 
    mutate(
      file_name = file 
    )
  }) 


cn_data_RAW <- map_df(cn_files, function(file) {
  d <- read_csv(file) %>% 
    count() %>% 
    mutate(
      file_name = file, 
    )
  }) 

#Tentatively setting minimum row to be 180, so we only read in files with more than 180 rows

MIN_ROW = 180

us_data <- map_df((us_data_RAW %>% filter(n > MIN_ROW))$file_name,
                  function(file){
                    d <- read_csv(file)
                  }) %>% 
  mutate(culture = "US") %>%
  # for version compatibility issue 
  mutate(labels_locations = NA_character_) %>% 
  filter(trial_type != "prolific-id")


cn_data <- map_df((cn_data_RAW %>% filter(n > MIN_ROW))$file_name,
                  function(file){
                    d <- read_csv(file) %>% 
                      mutate(labels = as.character(labels))
                  })%>% 
  mutate(culture = "CN") %>% 
  # for version compatibility issue
  mutate(labels_locations = as.character(labels_locations), 
         ) %>% 
  filter(trial_type != "prolific-id")

# count number of raw participants: 
fun.count_s <- function(df){
  num_s <- df %>% distinct(subject) %>% count()
  return(num_s)
}

fun.count_s(us_data)
fun.count_s(cn_data)

```

There are `r fun.count_s(us_data)` US participants and `r fun.count_s(cn_data)` CN participants. 





3



# Merging data and extracting demogs and write to `2_merged` folder 

Here we combine the US data and CN data together
```{r message=FALSE, warning=FALSE}
#combine US and CN 
merged_data <- bind_rows(us_data,cn_data) 
  

#extract demographic and combine them together
us_demogs <- extract_demog(us_data, "US")
cn_demogs <- extract_demog(cn_data, "CN")  
merged_demogs <- bind_rows(us_demogs, cn_demogs)

write_csv(merged_data, MERGED_DATA_PATH)
write_csv(merged_demogs, MERGED_DEMOGS_PATH)

#take a look at the tables
#merged_data %>% datatable()
#merged_demogs %>% datatable()
```

# Sanity Check: participants feedback
```{r}
us_ff_table <- extract_funnel_feedback(MERGED_DATA_PATH, US_HUMANREAD_PATH, "US")
us_ff_table %>% datatable()

cn_ff_table <- extract_funnel_feedback(MERGED_DATA_PATH, CN_HUMANREAD_PATH, "CN")
cn_ff_table %>% datatable()
```

# If no raw data, start here!
```{r}
merged_data <- read_csv(MERGED_DATA_PATH)

```

# Exclusion 



## Based on demographic {.tabset}

demographic exclusion: 
- abroad experience region don't fit 
- language fluency > 3 


```{r}

us_trimmed_demog <- extract_demog(merged_data, "US")
cn_trimmed_demog <- extract_demog(merged_data, "CN")

# detail_table == TRUE will print out participant info
demog_exclusion(us_trimmed_demog, "US", 
                check_exclusion = TRUE, 
                detail_table = FALSE) 
demog_exclusion(cn_trimmed_demog, "CN",
                check_exclusion = TRUE, 
                detail_table = FALSE) 


demog_ex_table_us <- demog_exclusion(us_trimmed_demog, "US", 
                check_exclusion = FALSE, 
                detail_table = TRUE) 


demog_ex_table_cn <- demog_exclusion(cn_trimmed_demog, "CN", 
                check_exclusion = FALSE, 
                detail_table = TRUE) 

demog_ex_id_us <- demog_ex_table_us %>% 
  filter(reason_abroad == TRUE) %>% 
  pull(subject)

demog_ex_id_cn <- demog_ex_table_cn %>% 
  filter(reason_abroad == TRUE) %>% 
  pull(subject)

#demog_ex_id_cn <- c()#too high for Chinese participants
#demog_ex_id_us <- c()# also too high for US participants (40 out of 133!)
demog_ex_id <- c(demog_ex_id_us, demog_ex_id_cn)


```
## DEMOG TABLE
```{r}
demog_ex_table_us <- demog_exclusion(us_trimmed_demog, "US", 
                                  check_exclusion = FALSE, 
                                  detail_table = TRUE) 
demog_ex_table_cn <- demog_exclusion(cn_trimmed_demog, "CN", 
                                  check_exclusion = FALSE, 
                                  detail_table = TRUE) 

US_total <- fun.count_s(us_data)$n
CN_total <- fun.count_s(cn_data)$n

demog_ex_table_us %>% 
  group_by(reason_abroad, reason_language) %>% 
  count() %>% 
  mutate(
    exclude_percentage = n / US_total
  )

demog_ex_table_cn %>% 
  group_by(reason_abroad, reason_language) %>% 
  count() %>% 
  mutate(
    exclude_percentage = n / CN_total
  )
```


## language distribution 
```{r}
us_trimmed_demog <- extract_demog(merged_data, "US")
cn_trimmed_demog <- extract_demog(merged_data, "CN")
demog <- bind_rows(us_trimmed_demog, cn_trimmed_demog)

demog %>% 
  filter(demog_question == "lang_ud" | demog_question == "lang_sp") %>% 
  mutate(demog_response = as.numeric(demog_response)) %>% 
  ggplot(aes(x = demog_response)) + 
  geom_histogram(bins = 10) + 
  facet_grid(culture~demog_question)
```



## Based on non-human coder task

- task-based exclusion: 
  - Ebbinghaus: side bias, > 90% trials pressed button on one side
  - RMTS: side bias, all trials pressed button on one side
  - self_inflation: the number of circles drawn do not correspond to the number of lables provided 
  - Free description and Causal attribution: >.25 uncodeable study 

- completion-based exclusion (unlikely): in one task the missing / unusable trials > 0.25 

```{r}
# Culture string is necessary because we also want to read from human annotated data

task_exclusion(filter(merged_data, culture == "US"), 
                                culture = "US", 
                                include_annotation = FALSE, 
                                check_exclusion = TRUE, 
                                detail_table = FALSE)

task_exclusion(filter(merged_data, culture == "CN"), 
                                culture = "CN", 
                                include_annotation = FALSE, 
                                check_exclusion = TRUE, 
                                detail_table = FALSE)

```





```{r}
task_ex_id_us <- task_exclusion(filter(merged_data, culture == "US"), 
                                culture = "US", 
                                include_annotation = FALSE, 
                                check_exclusion = FALSE)


task_ex_id_cn <- task_exclusion(filter(merged_data, culture == "CN"),
                                culture = "CN", 
                                include_annotation = FALSE, 
                                check_exclusion = FALSE)


# current ignoring circle drawing
complete_ex_id <- complete_exclusion(merged_data)

ex_id <- c(task_ex_id_us,task_ex_id_cn,complete_ex_id, demog_ex_id)
ex_id <- ex_id[!duplicated(ex_id)]

task_trimmed_d <- merged_data %>%
     filter(
       !(subject %in% ex_id)
     )

write_csv(task_trimmed_d, TRIMMED_DATA_PATH)
```



# Extract Human coders required task
## Create spreadsheet for human coders (after first round of exclusion)

- Features to have: automatically detected already coded ones and transferred to the newer 
First detect subjects who have been coded 
```{r}
CODED_US_FD_PATH <- here("data/annotated/US/us_fd_coded.csv")
CODED_US_CA_PATH <- here("data/annotated/US/us_ca_coded.csv")
CODED_US_SI_PATH <- here("data/annotated/US/us_si_coded.csv")

CODED_CN_FD_PATH <- here("data/annotated/CN/cn_fd_merged_coded.csv")
CODED_CN_CA_PATH <- here("data/annotated/CN/cn_ca_merged_coded.csv")
CODED_CN_SI_PATH <- here("data/annotated/CN/cn_si_merged_coded.csv")

get_coded_sbj <- function(PATH){
  coded_df <- read_csv(PATH)
  coded_sbj <- coded_df %>% 
  select(subject) %>% 
  distinct() %>% 
  pull()
  return(coded_sbj)
}

# get all the subjects who have been coded 

us_ca_coded_sbj <- get_coded_sbj(CODED_US_CA_PATH)
us_fd_coded_sbj <- get_coded_sbj(CODED_US_FD_PATH)
us_si_coded_sbj <- get_coded_sbj(CODED_US_SI_PATH)

cn_ca_coded_sbj <- get_coded_sbj(CODED_CN_CA_PATH)
cn_fd_coded_sbj <- get_coded_sbj(CODED_CN_FD_PATH)
cn_si_coded_sbj <- get_coded_sbj(CODED_CN_SI_PATH)

```


first round getting all the raw ones: 
```{r}
#cn_tba_fd_table <- extract_HIT_table(TRIMMED_DATA_PATH,CN_TBA_FD_PATH, "CN", "FD")
#cn_tba_ca_table <- extract_HIT_table(TRIMMED_DATA_PATH,CN_TBA_CA_PATH, "CN", "CA")

us_tba_fd_table <- extract_HIT_table(TRIMMED_DATA_PATH,US_TBA_FD_PATH, "US", "FD") 
us_tba_ca_table <- extract_HIT_table(TRIMMED_DATA_PATH,US_TBA_CA_PATH, "US", "CA") 
```



we need to filter out the already coded cn data in the newer spreadsheet
```{r}
# this won't work when all the participants have been coded 
#cn_tba_fd_table <- extract_HIT_table(TRIMMED_DATA_PATH,CN_TBA_FD_PATH, "CN", "FD", 
                                     #coded_subject = coded_cn_fd_sbj) 

#cn_tba_ca_table <- extract_HIT_table(TRIMMED_DATA_PATH, CN_TBA_CA_PATH, "CN", "CA")

us_tba_fd_table <- extract_HIT_table(TRIMMED_DATA_PATH,US_TBA_FD_PATH, "US", "FD",
                                     coded_subject = us_fd_coded_sbj) 
us_tba_ca_table <- extract_HIT_table(TRIMMED_DATA_PATH,US_TBA_CA_PATH, "US", "CA", 
                                     coded_subject = us_ca_coded_sbj) 
```


## assume already coded, Exclude based on human coders
```{r}
# take a look at distribution
task_exclusion(filter(merged_data, culture == "US"), 
                                culture = "US", 
                                include_annotation = TRUE, 
                                check_exclusion = TRUE, 
                                detail_table = FALSE)

task_exclusion(filter(merged_data, culture == "CN"), 
                                culture = "CN", 
                                include_annotation = TRUE, 
                                check_exclusion = TRUE, 
                                detail_table = FALSE)
```

## TASK TABLE 
```{r}
df.us_task_ex <- task_exclusion(filter(merged_data, culture == "US"), 
                                culture = "US", 
                                include_annotation = TRUE, 
                                check_exclusion = TRUE, 
                                detail_table = TRUE)

df.cn_task_ex <- task_exclusion(filter(merged_data, culture == "CN"), 
                                culture = "CN", 
                                include_annotation = TRUE, 
                                check_exclusion = TRUE, 
                                detail_table = TRUE)

df.us_task_ex %>% 
  pivot_longer(reason_EBB:reason_SI, 
               names_to = "task_name", values_to = "exclude") %>% 
  filter(exclude == TRUE) %>% 
  group_by(task_name) %>% 
  count() %>% 
  mutate(exclude_percent = n/US_total)

df.cn_task_ex %>% 
  pivot_longer(reason_EBB:reason_SI, 
               names_to = "task_name", values_to = "exclude") %>% 
  filter(exclude == TRUE) %>% 
  group_by(task_name) %>% 
  count() %>% 
  mutate(exclude_percent = n/CN_total)

```



# SUMMARIZE EXCLUSION REASON 
```{r}
merged_demogs %>% 
  group_by(culture) %>% 
  distinct(subject) %>% 
  count()

df.us_demog_ex %>% 
  distinct(subject) %>% 
  count()

df.cn_demog_ex %>% 
  distinct(subject) %>% 
  count()

df.us_task_ex %>% 
  distinct(subject) %>% 
  count()

df.cn_demog_ex %>% 
  distinct(subject) %>% 
  count()
```



```{r}
df.us_demog_ex<- demog_exclusion(filter(merged_demogs, culture == "US"),
                                  culture == "US", 
                                  check_exclusion = FALSE, 
                                  detail_table = TRUE) 
df.cn_demog_ex <- demog_exclusion(filter(merged_demogs, culture == "CN"),
                                  culture == "CN", 
                                  check_exclusion = FALSE, 
                                  detail_table = TRUE) 

df.us_task_ex <- task_exclusion(filter(merged_data, culture == "US"), 
                                culture = "US", 
                                include_annotation = TRUE, 
                                check_exclusion = TRUE, 
                                detail_table = TRUE)

df.cn_task_ex <- task_exclusion(filter(merged_data, culture == "CN"), 
                                culture = "CN", 
                                include_annotation = TRUE, 
                                check_exclusion = TRUE, 
                                detail_table = TRUE)


```

```{r}
df.us_all_ex <- left_join(df.us_demog_ex, 
                          df.us_task_ex, by = "subject")
df.cn_all_ex <- left_join(df.cn_demog_ex, 
                          df.cn_task_ex, by = "subject")



df.us_all_ex  
```

```{r}
HAND_EXCLUSION <- c(
                  # participant requested 
                  "SS1609806859776"
                  
)

tidy_d <- read_csv(here("data/4_processed/tidy_main.csv")) 
```

```{r}
df.us_all_ex %>% 
  filter(reason_abroad) %>% 
  distinct(subject) %>% 
  count()

df.cn_all_ex %>% 
  filter(reason_abroad | reason_EBB | reason_CA | reason_FD | reason_HZ | reason_RMTS | reason_SI) %>% 
  distinct(subject) %>% 
  count()

df.all_ex <- bind_rows(df.us_all_ex, df.cn_task_ex)

df.all_ex %>% 
  distinct(subject) %>% 
  count()

tidy_d %>% 
  distinct(subject) %>% 
  count()
```

```{r}
final_sbj <- tidy_d %>% 
  distinct(subject) %>% 
  pull()

full_sbj <- df.all_ex %>% 
  distinct(subject) %>% 
  pull()

exclude_sbj <- setdiff(full_sbj, final_sbj)
```

```{r}
# all have at least one instance 
df.us_all_ex %>% 
  filter(subject %in% exclude_sbj) %>% 
  filter(!(reason_abroad | reason_EBB | reason_CA | reason_FD | reason_HZ | reason_RMTS | reason_SI))


# somehow SS1609035138833 got excluded 
df.cn_all_ex %>% 
  filter(subject %in% exclude_sbj) %>% 
  filter(!(reason_abroad | reason_EBB | reason_CA | reason_FD | reason_HZ | reason_RMTS | reason_SI))

```
# FIGUREING OUT CN m
```{r}
merged_v <- read_csv(here("data/2_merged/merged_all.csv"))
trimmed_v <- read_csv(here("data/3_trimmed/trimmed_all.csv"))
merged_v %>% 
  filter(subject == "SS1609035138833")

"SS1609035138833" %in% complete_ex_id # it's because of complete!!!
```




```{r}
task_ex_id_us <- task_exclusion(filter(task_trimmed_d, culture == "US"), 
                                culture = "US", 
                                include_annotation = TRUE, 
                                check_exclusion = FALSE, 
                                detail_table = FALSE) 


task_ex_id_cn <- task_exclusion(filter(task_trimmed_d, culture == "CN"),
                                culture = "CN", 
                                include_annotation = TRUE, 
                                check_exclusion = FALSE, 
                                detail_table = FALSE)

ex_id <- c(task_ex_id_us,task_ex_id_cn)
ex_id <- ex_id[!duplicated(ex_id)]

trimmed_d <- task_trimmed_d %>%
     filter(
       !(subject %in% ex_id)
     ) %>%
  # to see if this can solve the weird encoding issue
  mutate(labels_locations = as.character(labels_locations))

us_trimmed_demogs <- extract_demog(trimmed_d, "US")
cn_trimmed_demogs <- extract_demog(trimmed_d, "CN") 
trimmed_demogs <- bind_rows(us_trimmed_demogs, cn_trimmed_demogs) 

write.csv(trimmed_d, TRIMMED_DATA_PATH)
write.csv(trimmed_demogs, TRIMMED_DEMOGS_PATH)
```

## Generate circle drawing and Create coding sheet for circle 
### Circles!
```{r}
# note that now we exlcude the ones already coded!
us_si <- map_df((us_data_RAW %>% filter(n > MIN_ROW))$file_name,
                  function(file){
                    d <- read_csv(file) %>% 
                      mutate(labels = as.character(labels)) %>% 
                      filter(trial_type == "konva-draw-circle")
                  }) %>% 
   filter(
       !(subject %in% ex_id)
     ) %>% 
  mutate(culture = "US") %>% 
  select(subject, culture, locations, labels, labels_locations) %>% 
  filter(!is.na(labels)) %>% 
  filter(!(subject %in% us_si_coded_sbj)) %>% 
  filter(!subject %in% ex_id)


cn_si <- map_df((cn_data_RAW %>% filter(n > MIN_ROW))$file_name,
                  function(file){
                    d <- read_csv(file) %>% 
                      mutate(labels = as.character(labels)) %>% 
                      filter(trial_type == "konva-draw-circle")
                  })%>% 
  filter(
       !(subject %in% ex_id)
     ) %>% 
  mutate(culture = "CN") %>% 
  select(subject, culture, locations, labels, labels_locations) %>% 
  filter(!is.na(labels))

save_image_new(us_si, US_CIRCLE_DIR)
#save_image_new(cn_si, CN_CIRCLE_DIR)
```

### Coding Sheet! 
```{r}

us_coding_sheet <- generate_coding_sheet(us_si)
#cn_coding_sheet <- generate_coding_sheet(cn_si)

write_csv(us_coding_sheet, US_CIRCLE_CODING_PATH)
#write_csv(cn_coding_sheet, CN_CIRCLE_CODING_PATH)
```




# Tidy up the dataset
clean up the trimmed data into tidy format

```{r message=FALSE}
TASK <- c("EBB", 
          "RMTS", 
          "SI",
          "HZ", 
          "CP", 
          "RV",
          "FD",
          "CA"
          )

# when ignoring hand coding, use task_trimmed_d
#main <- TASK %>% 
#  map_df(~ eval(parse(text = paste0("get_", ., "_main(task_trimmed_d)"))))

# when not ignoring hand coding, use trimmed_d 
main <- TASK %>% 
  map_df(~ eval(parse(text = paste0("get_", ., "_main(trimmed_d)"))))

write.csv(main,PROCESSED_MAIN_PATH)


#write.csv(main_final)

#main %>% datatable()
```

# Tidy up demographic information 
```{r}
final_main_subj <- read_csv(PROCESSED_MAIN_PATH) %>% 
  distinct(subject) %>% 
  pull
final_trimmed_demog <- read_csv(TRIMMED_DEMOGS_PATH) %>% 
  filter(subject %in% final_main_subj)

```

```{r}
main %>% filter(task_name == "HZ") %>% filter(resp_type == "hz_height")
```


