---
title: "03_polimodel"
author: "anjie"
date: "2/22/2021"
output: html_document
---

```{r}
library(tidyverse)
library(patchwork)
library(here)

#source(here("scripts/poli_model_wave2.R"))

```

reproducing poli: https://rpubs.com/anjiecao/729261


# feature based attempts

## set up the parameter 

```{r}
# the length of vectors that contains 1 or 0
TOTAL_FEATURE_N = 50
COMPLEX_FEATURE_N = 20  
# FD: down the road can try something like rbinom(20, 1, 0.5)

# number of feature sampled per look 
EACH_LOOK_N = 5


```

## generate stimuli: 
```{r}
f.generate_stimuli_vector <- function(total_feature_n, stimuli_feature_n){

    vec <- c(rep(0, total_feature_n - stimuli_feature_n), rep(1, stimuli_feature_n))
  return(sample(vec))

}

f.generate_stimuli_vector(TOTAL_FEATURE_N, COMPLEX_FEATURE_N)
```

## generate similar / dissimilar stimuli 
```{r}
# FD: try more continuous way of scaling similarity and try out different parameters 

f.generate_stimuli_similarity <- function(original_stimuli, similarity){
  
   non_overlapping_feature <- ifelse(similarity == "similar", .2, .8)
  
    # first figure out where the 1s are at 
    feature_pos <- which(original_stimuli %in% c(1))
    non_feature_pos <- which(original_stimuli %in% c(0))
    
    # change 1 to 0
    feature_change_pos <- sample(feature_pos, 
                            non_overlapping_feature * length(feature_pos), 
                            replace = FALSE)
    
    new_stim <- replace(original_stimuli, feature_change_pos, 0)
    
    # change 0 to 1 
    non_feature_change_pos <- sample(non_feature_pos, 
                            non_overlapping_feature * length(feature_pos), 
                            replace = FALSE)
    
    new_stim <- replace(new_stim, non_feature_change_pos, 1)
    
  
  return (new_stim)  

}

# example: 
example_vector <- f.generate_stimuli_vector(10, 5)
similar_vector <- f.generate_stimuli_similarity(example_vector, "similar")
dissimilar_vector <- f.generate_stimuli_similarity(example_vector, "dissimilar")

example_vector
similar_vector
dissimilar_vector
```

## create a stimuli sequence 

```{r}

TOTAL_FEATURE_N = 50
COMPLEX_FEATURE_N = 20  
SIMPLE_FEATURE_N = 10
f.block_sequence <- function(total_feature_n, 
                             simple_feature_n, 
                             complex_feature_n,
                             block_length, 
                             deviant_pos, 
                             complexity, 
                             similarity){
  
  TOTAL_FEATURE_N = total_feature_n  
  # the number of 1 in the feature vector 
  SIMPLE_FEATURE_N = simple_feature_n
  COMPLEX_FEATURE_N = complex_feature_n  
  
  feature_n <- ifelse(complexity == "complex", COMPLEX_FEATURE_N, SIMPLE_FEATURE_N)
  background_stim <- f.generate_stimuli_vector(TOTAL_FEATURE_N, feature_n)
  deviant_stim <- f.generate_stimuli_similarity(background_stim, similarity)
  
  block_list <- replicate(block_length, background_stim, simplify = FALSE)
  
  block_list[deviant_pos] <- replicate(length(deviant_pos), 
                                       deviant_stim, 
                                       simplify = FALSE)
  
  return(block_list)

}

example_block_complex_similar <- f.block_sequence(
  TOTAL_FEATURE_N, 
  SIMPLE_FEATURE_N, 
  COMPLEX_FEATURE_N, 
  8, c(7), "complex", "similar")
example_block_complex_dissimilar <- f.block_sequence(
  TOTAL_FEATURE_N, 
  SIMPLE_FEATURE_N, 
  COMPLEX_FEATURE_N, 
  8, c(7), "complex", "dissimilar")
example_block_simple_similar <- f.block_sequence(
  TOTAL_FEATURE_N, 
  SIMPLE_FEATURE_N, 
  COMPLEX_FEATURE_N, 
  8, c(7), "simple", "similar")
example_block_simple_dissimilar <- f.block_sequence(
  TOTAL_FEATURE_N, 
  SIMPLE_FEATURE_N, 
  COMPLEX_FEATURE_N, 8, c(7), "simple", "dissimilar")
example_block_complex_similar
example_block_simple_similar
```

## each observation 

```{r}
#updating p(features) --> pay attention to a random set of two positive features
#updating p(features): noisy process that only samples a random subset of positive features

# not sure if it is better to assume proportion based or to assume feature number based
# currently implementing number based 
NUM_FEATURE_SAMPLE_PER_OBSERVATION <- 3

make_observation <- function(stimuli, feature_sample){
  
  #figure out the feature position  
  feature_pos <- which(stimuli %in% c(1))
  sampled_feature <- sample(feature_pos, 
                            feature_sample, 
                            replace = FALSE)
  observation <- rep(0, length(stimuli))
  observation[sampled_feature] <- 1
  
  return(observation)
  
}

example_block_complex_similar 
example_observation <- lapply(example_block_complex_similar, make_observation, 
       NUM_FEATURE_SAMPLE_PER_OBSERVATION)
example_observation
```




# naive bayes example 
```{r}
example_block_complex_similar

prior <- replicate(length(example_block_complex_similar[[1]]), c(1,1), simplify = FALSE)

beta_count <- list()

for (trial in 1:length(example_block_complex_similar)){
  current_observation = example_block_complex_similar[[trial]]
  
  if (trial == 1){
    current_trial = prior 
  }else{
    current_trial = beta_count[[trial-1]]
  }
  
  for (feature_index in 1:length(current_trial)){
    
    feature_bin = current_trial[[feature_index]]
    
    if (current_observation[[feature_index]] == 1){
      current_trial[[feature_index]] <- c(current_trial[[feature_index]][1] + 1, 
                                          current_trial[[feature_index]][2])
    }else{
      current_trial[[feature_index]] <- c(current_trial[[feature_index]][1], 
                                          current_trial[[feature_index]][2] + 1)
    }
    
  }
  beta_count[[trial]] <- current_trial
  
  
}


```


```{r}
# calculate probability for each feature
feature_prob <- lapply(beta_count, 
       function(x) lapply(x, 
                          function(x)x[[1]]/(x[[1]] + x[[2]])))


update_prob_list <- list()

for (trial in 1:length(example_block_complex_similar)) {
      current_observation = example_block_complex_similar[[trial]]
      
      if (trial == 1){
          current_trial = replicate(length(current_observation), 
                                    0.5)
      }else{
          current_trial = feature_prob[[trial-1]]
      }
      
      
      # loop through each observation feature vector
      new_probability = c()
      for (feature in 1:length(current_observation)){
        if (current_observation[[feature]] == 0){
          current_trial[[feature]] <- 1 - current_trial[[feature]]
        }
      }
      update_prob_list[[trial]] <- current_trial
    
}

update_prob_list







creature_prob <- lapply(update_prob_list, 
       function(x)prod(as.data.frame(x)))

feature_suprirse <- lapply(update_prob_list, 
       function(x) lapply(x, 
                          function(x)-log2(x)))

sum_feature_surprise <- lapply(feature_suprirse, 
                               function(x)sum(as.data.frame(x)))
```


```{r}
tibble("lol" = creature_prob) %>% 
  mutate( trial = row_number()) %>% 
  unnest(lol) %>% 
  ggplot(aes(x = trial, y = lol)) + 
  geom_point() + 
  geom_line()

tibble("lol" = sum_feature_surprise) %>% 
  mutate( trial = row_number()) %>% 
  unnest(lol) %>% 
  ggplot(aes(x = trial, y = lol)) + 
  geom_point() + 
  geom_line()
```












## trying to figure out how to update 
```{r}
# first convert to reasonable dataframe 
feature_index <- seq(example_observation[[1]])
as.data.frame(data.table::transpose(example_observation), 
              col.names = seq(length(example_observation))) %>% 
  mutate(
    trial_num = row_number()
  ) 
  
# not ideal just proof of concept need to figure out R details 
probability_df <- tibble(prob_trials = 0:length(example_observation), 
                         feature_1 = 0, 
                         feature_2 = 0,
                         feature_3 = 0, 
                         feature_4 = 0,
                         feature_5 = 0,
                         feature_6 = 0,
                         feature_7 = 0,
                         feature_8 = 0,
                         feature_9 = 0,
                         feature_10 = 0,
                         feature_11 = 0,
                         feature_12 = 0,
                         feature_13 = 0,
                         feature_14 = 0,
                         feature_15 = 0,
                         feature_16 = 0,
                         feature_17 = 0,
                         feature_18 = 0,
                         feature_19 = 0,
                         feature_20 = 0
                         )

count_df <- tibble(count_trials = 0:length(example_observation), 
                         feature_1 = 0, 
                         feature_2 = 0,
                         feature_3 = 0, 
                         feature_4 = 0,
                         feature_5 = 0,
                         feature_6 = 0,
                         feature_7 = 0,
                         feature_8 = 0,
                         feature_9 = 0,
                         feature_10 = 0,
                         feature_11 = 0,
                         feature_12 = 0,
                         feature_13 = 0,
                         feature_14 = 0,
                         feature_15 = 0,
                         feature_16 = 0,
                         feature_17 = 0,
                         feature_18 = 0,
                         feature_19 = 0,
                         feature_20 = 0
                         )


# not sure if the prior makes sense 
prior <- rep(1/length(example_observation[[1]]), length(example_observation[[1]]))
probability_df[1, 2:21] <- as.list(prior)

probability_df
count_df

for (i in 1:length(example_observation)) {
      count_df[count_df$count_trials == i, 2:21] <-  count_df[count_df$count_trials == i-1, 2:21]
      count_df[count_df$count_trials == i, 2:21] <- count_df[count_df$count_trials == i, 2:21] + as.list(example_observation[[i]])
      
      count_vect <- count_df %>% 
        select(-count_trials) %>% 
        slice(i+1)
      
      # updating the probability by normalizing everything 
      probability_df[probability_df$prob_trials == i, 2:21] <- as.list((count_vect + 1) / sum(count_vect + 1))
      
      #probability_df[probability_df$prob_trials == i, 2:21] <- as.list(1 / sum(count_vect) * count_vect)
}

## what should be the updating rule for probability? 
count_df
probability_df
```

```{r}
# ugliest code chunk ever! yuk! 
#example_observation <- example_block_complex_similar
example_observation <- lapply(example_block_complex_similar, make_observation, 
       9)

update_prob_list <- list()

for (i in 1:length(example_observation)) {
      current_observation = example_observation[[i]]
      current_prior = filter(probability_df, prob_trials == i-1) %>% as.vector()
      
      # loop through each observation feature vector
      new_probability = c()
      for (q in 2:length(current_prior)) {
        feature_prior = current_prior[q]
        if (current_observation[q-1] == 0){
          current_feature_prob = 1 - feature_prior
        }else if (current_observation[q-1] == 1){
          current_feature_prob = feature_prior
        }
        new_probability = c(new_probability, 
                            current_feature_prob)
        
      }
      update_prob_list[[i]] <- new_probability
    
}

updated_prob <- as.data.frame(do.call(rbind, update_prob_list)) %>% 
  unnest()
  

df.prob <- tibble("probability" = updated_prob %>% 
  as.matrix() %>% 
  Rfast::rowprods())

## multiply first then sum 
df.prob %>% 
  mutate(trial_num = row_number(), 
         surprise = -log2(probability)) %>% 
  ggplot(aes(x = trial_num, 
         y = surprise)) + 
  geom_point() + 
  geom_line() + 
  labs(title ="randomly sampling 9 features")
  
  
## calculate feature-based suprirse then sum 
updated_prob %>% 
  mutate(
    across(
      .fns = ~-log2(.))
  ) %>% 
  mutate(trial_num = row_number()) %>% 
  rowwise() %>% 
  mutate(
    sum_surprise = sum(across(), 
                       na.rm = TRUE)) %>% 
  ggplot(aes(x = trial_num, 
         y = sum_surprise)) + 
  geom_point() + 
  geom_line() + 
  labs("calculate feature-based surprise then sum together")
```














# single block using example sequence
```{r}
example_seq <- c(1,1,1,1,2,1)
single_block_dissimilar <- poli_model_pokebaby(example_seq, similar = FALSE) %>% 
  mutate(similarity = "dissimilar")

```



```{r}

single_block_similar <- poli_model_pokebaby(example_seq, similar = TRUE) %>% 
  mutate(similarity = "similar") 

single_block_similarity <- bind_rows(single_block_similar, single_block_dissimilar)


```


```{r}
 df.plot <- single_block_similarity %>% 
    select(trials, surprisal, predictability, learning_progress, similarity) %>% 
    pivot_longer(cols = c("surprisal", "predictability", "learning_progress"), 
                 names_to = "measure", 
                 values_to = "value") %>% 
    filter(trials != 0)
  
  surprise_plot <- df.plot %>% 
    filter(measure == "surprisal") %>% 
    ggplot(aes(x = trials, y = value, color = similarity)) + 
    geom_point(position = position_dodge(width = .1)) + 
    geom_line() + 
    ylab("surprise") #+ 
  #scale_x_continuous(breaks =seq(1,12,1))
  
  predictability_plot <- df.plot %>% 
    filter(measure == "predictability") %>% 
    ggplot(aes(x = trials, y = value, color = similarity)) + 
    geom_point(position = position_dodge(width = .1)) + 
    geom_line() + 
    ylab("predictability") #+ 
  #scale_x_continuous(breaks =seq(1,12,1))
  
  learning_progress_plot <- df.plot %>% 
    filter(measure == "learning_progress") %>% 
    ggplot(aes(x = trials, y = value, color = similarity)) + 
    geom_point(position = position_dodge(width = .1)) + 
    geom_line() + 
    ylab("learning_progress") #+ 
  #scale_x_continuous(breaks =seq(1,12,1))
  
  surprise_plot+predictability_plot+learning_progress_plot + plot_layout(ncol = 1)
```


