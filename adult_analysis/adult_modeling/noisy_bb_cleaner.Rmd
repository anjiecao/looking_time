---
title: "noisy_bb_cleaner"
author: "anjie"
date: "5/5/2021"
output: html_document
---

```{r}
library(tidyverse)
library(matrixStats)
library(here)

source(here("adult_modeling/scripts/grid_approximation.R"))
source(here("adult_modeling/scripts/noisy_update.R"))

```

# generate creature sequence 
this is easy fill in later 
```{r}


b_1 <- make_creature(total_feature = 20, 
                     
                     feature_theta = 0.8,   # currently assuming all situations where there are features the theta are the same 

                     feature_ratio = 0.4  #complexity controls for the proportion of the features 
                     )

d_1 <- make_dissimilar_creature(creature = b_1, 
                                dissimilar_ratio = .8)

generate_creature_sequence <- function(
  block_length, 
  deviant_number, 
  deviant_position, 
){
  
}
```

# generate creature sequence 

```{r}
noisy_observation_feature <- function(
  feature, 
  n_sample, 
  epsilon 
){
  real_features <- rep(feature, n_sample)
  noisy <- rbernoulli(p = epsilon, n = n_sample)
  return(ifelse(noisy, 1-real_features, real_features))
  
}


noisy_observation_creature <- function(
  creature, 
  n_sample, 
  epsilon
){
  sapply(creature, function(y){noisy_observation_feature(
    feature = y, 
    n_sample = n_sample, 
    epsilon = epsilon
  )})
  
}

```

## test creature 
```{r}
test_creature_background_theta <- c(0.01, 0.01, 0.01, 0.99, 0.99, 0.8)
test_creature_deviant_theta <- c(0.2, 0.8, 0.8, 0.2, 0.2, 0.9)
#test creature
# these will be a block [y_1, y_2, y_3, y_4, z_1, y_5]
y_1 <- sapply(test_creature_background_theta, function(x){rbernoulli(p = x, n = 1)})
y_2 <- sapply(test_creature_background_theta, function(x){rbernoulli(p = x, n = 1)})
y_3 <- sapply(test_creature_background_theta, function(x){rbernoulli(p = x, n = 1)})
y_4 <- sapply(test_creature_background_theta, function(x){rbernoulli(p = x, n = 1)})
z_1 <-  sapply(test_creature_deviant_theta, function(x){rbernoulli(p = x, n = 1)})
#y_5 <- sapply(test_creature_background_theta, function(x){rbernoulli(p = x, n = 1)})

# in each trial collects like 100 times
y_1_noisy_observation <- rbind(noisy_observation_creature(y_1, 20, 0.02))
y_2_noisy_observation <- rbind(noisy_observation_creature(y_2, 20, 0.02))
y_3_noisy_observation <-  rbind(noisy_observation_creature(y_3, 20, 0.02))
y_4_noisy_observation <-  rbind(noisy_observation_creature(y_4, 30, 0.2))
z_1_noisy_observation <-  rbind(noisy_observation_creature(z_1, 30, 0.2))


```

## sequential update 
```{r}
noisy_update <- function(observations,
                         grid_theta, grid_epsilon, 
                         alpha_prior = 1, beta_prior = 1, 
                         alpha_epsilon = 10, beta_epsilon = 1){
  
  observation_length
  
  
  
}
```

```{r}
theta_only <- first_update_grid_approximate_with_theta(feature_index = 1,
                                                                 thetas = seq(0.01, .99, .02),                                                                                 z_bar = z_bar, 
                                                       epsilon = .01,
                                                                   
                                                                                                                                                  alpha_theta = alpha_theta, beta_theta = beta_theta, alpha_epsilon = alpha_epsilon, beta_epsilon = beta_epsilon)
theta_and_epsilon <- first_update_grid_approximate_with_theta_and_epsilon(feature_index = 1,
                                                                                                                                                 z_bar = z_bar, 
                                                                                                                                                  alpha_theta = alpha_theta, beta_theta = beta_theta, alpha_epsilon = alpha_epsilon, beta_epsilon = beta_epsilon)
```

```{r}
theta_only


epsilon_normalized <- theta_and_epsilon %>% 
  group_by(theta, .drop = FALSE) %>% 
  summarize(normalized_log_posterior = unnormalized_log_posterior - logSumExp(unnormalized_log_posterior)) 


# #
# samps$log_posterior = samps$unnormalized_log_posterior - matrixStats::logSumExp(samps$unnormalized_log_posterior)
# 
# theta_posterior <- samps %>%
#   group_by(theta) %>%
#   summarise(log_posterior = matrixStats::logSumExp(log_posterior) + 
#               log(1/length(log_posterior))) %>%
#   mutate(posterior = exp(log_posterior))


theta_and_epsilon$log_posterior <- theta_and_epsilon$unnormalized_log_posterior - matrixStats::logSumExp(theta_and_epsilon$unnormalized_log_posterior)

new_theta_posterior <- theta_and_epsilon %>% 
  filter(epsilon == 0.03) %>%
  group_by(theta) %>% 
  summarise(log_posterior = matrixStats::logSumExp(log_posterior) +
              log(1/length(log_posterior))) 

  
  
new_theta_and_epsilon <- theta_and_epsilon %>% 
  filter(epsilon == 0.5) %>% 
  group_by(theta, .drop = FALSE) %>% 
  summarise(
    
    normalized_log_posterior = unnormalized_log_posterior - logSumExp(unnormalized_log_posterior), 
     log_posterior = matrixStats::logSumExp(normalized_log_posterior) + 
          log(1/length(normalized_log_posterior))
  ) 
```

```{r}
theta_and_epsilon %>% 
  group_by(theta) %>% 
     summarise(
   #     #unnormalized_log_posterior = matrixStats::logSumExp(unnormalized_log_posterior) + 
   #     #     log(1/length(unnormalized_log_posterior)), 
        log_posterior = matrixStats::logSumExp(normalized_log_posterior) + 
          log(1/length(normalized_log_posterior))
   #     
   #     #unnormalized_log_posterior = matrixStats::logSumExp(unnormalized_log_posterior) + 
   #    #   log(1/length(unnormalized_log_posterior)), 
   #    # log_posterior = matrixStats::logSumExp(normalized_log_posterior) + 
   #     #          log(1/length(normalized_log_posterior))
      ) 
```


```{r}
theta <- first_update_grid_approximate_with_theta(feature_index, 
                                                  )
```



```{r}
z_bar 

theta_only %>% 
  ggplot(aes(x = theta, y = exp(normalized_log_posterior))) + 
  geom_point()

new_theta_posterior %>% 
  ggplot(aes(x = theta, y = exp(log_posterior))) + 
  geom_point()
```



```{r}
grid_theta <- seq(0.01, 0.99, 0.05)
grid_epsilon <- seq(0.01, 0.99, 0.05)

three_observations <- rbind(y_1_noisy_observation, 
                            y_2_noisy_observation, 
                            y_3_noisy_observation)

updates = nrow(three_observations)


# let's just look at 10 updates first

datalist = list()
for (i in seq(1, updates, 1)){
  
  post_first_update_theta_epsilon_approx <- grid_approximate_creature_with_theta_and_epsilon(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = three_observations[1:i, ], 
  alpha_prior = 1, 
  beta_prior = 1,
  alpha_epsilon = 10, 
  beta_epsilon = 1
) %>% 
    mutate(update_number = i)
  
   datalist[[i]] <-  post_first_update_theta_epsilon_approx
  
  
  
}
all_updates <- dplyr::bind_rows(datalist)



```

is it something wrong with doing grid appproximation on epsilon? 

```{r}
datalist = list()
for (i in seq(1, updates, 1)){
  
  post_first_update_theta_approx <- grid_approximate_creature_with_theta(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = three_observations[1:i, ], 
  alpha_prior = 1, 
  beta_prior = 1,
  alpha_epsilon = 10, 
  beta_epsilon = 1
) %>% 
    mutate(update_number = i) %>% 
    rename(log_posterior = normalized_log_posterior)
  
   datalist[[i]] <-  post_first_update_theta_approx
  
  
  
}
all_updates_theta <- dplyr::bind_rows(datalist)


```




# it looks a little reversed to me but will worry abt it later 
```{r}
y_1
y_2
y_3
all_updates %>% 
  filter(update_number %in% seq(1, 20, 1)) %>% 
  ggplot(aes(x = theta, y = exp(log_posterior), color = update_number)) + 
  geom_point()+ 
  facet_wrap(~feature_index)
```


#KL divergence starts here 


$$EIG(y) = \sum_{y'_{t+1}} { D_{KL} ( p(\theta | y_{1..y_{t+1}}) || p(\theta | y_{1..y_{t}})  ) p(y_{t+1} | \theta) }$$
actually not so sure if it makes sense to calculate EIG based on y because we don't really know anythinga bt it 

what about just doing it based on z? 

http://todd.gureckislab.org/2021/05/05/negative-information

so if the formula was: 

$$D_{KL}(p(x) || q(x)) = \sum_{x \in X} p(x) log\frac{p(x)}{q(x)}$$


in our case it will be 

$$D_{KL}(p(\theta|z_{i+1}) || p(\theta|z_{i})) = \sum_{x \in X} p(\theta|z_{i+1})  log\frac{p(\theta|z_{i+1})}{p(\theta|z_{i}))}$$
maybe we can pretend theta is concrete like we've been doing? so effectively we will have 

$$D_{KL}(p(\theta|z_{i+1}) || p(\theta|z_{i})) = \sum_{\theta \in [\theta_{1}, \theta_{2}...]} p(\theta|z_{i+1})  log\frac{p(\theta|z_{i+1})}{p(\theta|z_{i})}$$

```{r}


kl_df_theta_only <- get_kl_for_feature(feature = 3, 
                  distribution_df = all_updates_theta) 


kl_df_theta_espilon <- get_kl_for_feature(feature = 3, 
                  distribution_df = all_updates) 
```

```{r}
kl_df_theta_espilon %>% 
  ggplot(aes(x = udpate_step, y = kl), 
        ) + 
  geom_line() #+
  #geom_point(aes(x = kl_df$udpate_step, y = three_observations[,3][2:length(three_observations[,3])]))

kl_df_theta_only %>% 
  ggplot(aes(x = udpate_step, y = kl), 
        ) + 
  geom_line()

```

```{r}

all_updates_theta_kl <- get_kl_for_creature(all_updates_theta)

all_updates_theta_kl %>% 
  group_by(update_step) %>% 
  summarise(kl_creature = sum(kl)) %>% 
  ggplot(aes(x = update_step, 
             y = kl_creature)) + 
  geom_line() #+ 
  #facet_wrap(~feature_index)
  
```



```{r}
all_updates
```






















```{r}
grid_theta <- seq(0.01, 0.9, 0.05)
grid_epsilon <- seq(0.01, 0.9, 0.05)


post_first_update_theta_approx <- grid_approximate_creature_with_theta_initial(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = y_1_noisy_observation, 
  alpha_prior = 1, 
  beta_prior = 1,
  alpha_epsilon = 10, 
  beta_epsilon = 1
)


post_first_update_theta_epsilon_approx <- grid_approximate_creature_with_theta_and_epsilon_initial(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = y_1_noisy_observation, 
  alpha_prior = 1, 
  beta_prior = 1,
  alpha_epsilon = 10, 
  beta_epsilon = 1
)

post_first_update_theta_approx
post_first_update_theta_epsilon_approx
```






```{r}
post_second_update_theta_approx <- grid_approximate_creature_with_theta_continuous(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = y_2_noisy_observation,  
  updated_posterior_df = post_first_update_theta_approx,
  alpha_epsilon = 10, 
  beta_epsilon = 1
)

# current having weird issue around 0.1; R refuses to recognize it is there
# leading to weird issue related to log probablity having numeric(0) and problem with normalizing 
post_second_update_theta_epsilon_approx <- grid_approximate_creature_with_theta_and_epsilon_continuous(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = y_2_noisy_observation,  
  updated_posterior_df = post_first_update_theta_approx,
  alpha_epsilon = 10, 
  beta_epsilon = 1
)
```

check if we are actually doing anything meaningful: 

```{r}
test_creature_background_theta <- c(0.2, 0.2, 0.2, 0.8, 0.8, 0.3)

first_update <- post_first_update_theta_approx %>% 
  mutate(update_number = 1)
second_update <- post_second_update_theta_approx %>% 
  mutate(update_number = 2)

two_updates <- bind_rows(first_update, second_update)

two_updates %>% 
  ggplot(aes(x = theta, 
             y = normalized_log_posterior, 
             color = update_number)) + 
  geom_point()+
  facet_wrap(~feature_index)
```
actually not entirely sure. probably because we are not approximating over epsilon as well? anyway we can try to do this one more time

```{r}


post_third_update_theta_approx <- grid_approximate_creature_with_theta_continuous(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = y_3_noisy_observation,  
  updated_posterior_df = post_second_update_theta_approx,
  alpha_epsilon = 10, 
  beta_epsilon = 1
) %>% 
  mutate(update_number = 3)


post_third_update_theta_epsilon_approx <- grid_approximate_creature_with_theta_and_epsilon_continuous(
  grid_theta = grid_theta, 
  grid_epsilon = grid_epsilon, 
  noisy_creature_observation = y_3_noisy_observation,  
  updated_posterior_df = post_first_update_theta_approx,
  alpha_epsilon = 10, 
  beta_epsilon = 1
)%>% 
  mutate(update_number = 3)




three_updates <- bind_rows(two_updates, post_third_update_theta_approx)


three_updates %>% 
  ggplot(aes(x = theta, 
             y = normalized_log_posterior, 
             color = update_number)) + 
  geom_point()+
  facet_wrap(~feature_index)

```

maybe? not entirely sure. 

look at grid over the epsilon's too
```{r}
two_updates <- bind_rows(post_first_update_theta_epsilon_approx %>% mutate(update_num = 1), 
                          post_second_update_theta_epsilon_approx %>% 
                            mutate(update_num = 2))
                          
two_updates %>% 
  ggplot(aes(x = theta, 
             y = exp(log_posterior), 
             color = update_num)) + 
  geom_point()+
  facet_wrap(~feature_index)
```

ugh might be right? not sure, but let's do the surprisal 

gal: take the surprisal for each value of theta, and take the average of those surprisals weighed by p(theta = this_particular_value_of_theta|z) (

$$p(\theta = \theta_{k} | z) $$

KL(P || Q)
Where the “||” operator indicates “divergence” or Ps divergence from Q.



https://machinelearningmastery.com/divergence-between-probability-distributions/#:~:text=KL%20divergence%20can%20be%20calculated,of%20the%20event%20in%20P.&text=The%20value%20within%20the%20sum%20is%20the%20divergence%20for%20a%20given%20event.

```{r}

```



```{r}
post_first_update_theta_approx
post_second_update_theta_approx

# we will use 
y_2_noisy_observation
# to calculate based on
y_1
post_first_update_theta_approx %>% 
  mutate(probability = exp(normalized_log_posterior)) %>% 
  ggplot(aes(x = theta, y = probability)) + 
  geom_line() +
  facet_wrap(~feature_index)
```

```{r}

calculate_surprise_from_trial <- function(observations, 
                                          posterior_df){
  
  
}

calculate_feature_suprirse_from_observation <- function(observation, new_prior_df){
  
  thetas <- new_prior_df$theta 
  lp_thetas <- new_prior_df$normalized_log_posterior 
  if (observation == 1){
    surprise <- -lp_thetas  #negative log probability
    weighted_mean_surprise <- weighted.mean(x = surprise, w = lp_thetas) 
  }else {
    # 1 - p(theta) 
    # we have log(p(theta))
    # this might cause underflow problem 
    surprise <- -log(1- exp(lp_thetas))
    
  }
  
}
```





