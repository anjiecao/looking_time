---
title: "noisy_bb_copycat"
author: "anjie"
date: "5/4/2021"
output: html_document
---

```{r}
library(tidyverse)
library(matrixStats)
```



# inference 

this is the ultimate posterior we want to get 
$$p(\theta | z) = p(z | \theta)p(\theta)p(\epsilon)$$


```{r}
lp_theta_given_z <- function(z_bar, 
                             theta, epsilon, 
                             alpha_theta, beta_theta, 
                             alpha_epsilon, beta_epsilon) {
  #print(lp_z_given_theta(z_bar, theta, epsilon))
  #print(lp_theta(theta, alpha_theta, beta_theta))
  #print(lp_episolon(epsilon, alpha_epsilon, beta_epsilon))
  
  lp_z_given_theta(z_bar, theta, epsilon) + 
    lp_theta(theta, alpha_theta, beta_theta) + 
    lp_episolon(epsilon, alpha_epsilon, beta_epsilon)
}
```


$$p(\bar{z}|\theta) = \prod_{i \in 1....n} \prod_{j \in 1...n} p(z_{ij} |\theta) $$

```{r}
#z_bar is a vector that keeps track of all z_ij
#z bar is not probability yet, is 1/0 
lp_z_given_theta <- function(z_bar, 
                             theta, 
                             episolon){
  
  # doing sum because we are keeping track of all the log probabilities  
  sum(sapply(z_bar, function(x){lp_z_ij_given_theta(zij = x, 
                                            theta = theta, 
                                            episolon = episolon)}))
  
  
}
```


$$p(z_{ij} | \theta) = p(z_{ij}|y_i)p(y_i | \theta)$$ 
$$p(z_{ij}|y_i)p(y_i | \theta) = p(z_{ij}|y_i = 1)p(y_i = 1 | \theta) + p(z_{ij}|y_i = 0)p(y_i = 0 | \theta)$$


```{r}
lp_z_ij_given_theta <- function(zij, theta, episolon){
  
  
  #print()
  #print(lp_z_ij_given_y(zij = zij, yi = 1, episolon = episolon) + lp_yi_given_theta(yi = 1, theta = theta ))
  #print(lp_z_ij_given_y(zij = zij, yi = 0, episolon = episolon) + lp_yi_given_theta(yi = 0, theta = theta))
  
  logSumExp(
    c(lp_z_ij_given_y(zij = zij, yi = 1, episolon = episolon) + lp_yi_given_theta(yi = 1, theta = theta ), 
    lp_z_ij_given_y(zij = zij, yi = 0, episolon = episolon) + lp_yi_given_theta(yi = 0, theta = theta))
  )
  
}
```


```{r}
lp_z_ij_given_y <- function(zij, yi, episolon){
  if (zij == yi){
    log(1 - episolon)
  }else{
    log(episolon)
  }
}

lp_yi_given_theta <- function(yi, theta){
  # a cooler way to say that if yi = 1 then theta if yi = 0 then yi = 1-theta? 
  dbinom(yi, size = 1, prob = theta, log = TRUE)
}


```


```{r}
lp_theta <- function(theta, alpha_theta, beta_theta){
  # actually i think i'm still a little unsure of what the relationship between theta and p(theta) is
  dbeta(x = theta, shape1 = alpha_theta, shape2 = beta_theta, log = TRUE)
}

lp_episolon <- function(theta, alpha_episolon, beta_episolon){
  dbeta(x = theta, shape1 = alpha_episolon, shape2 = beta_episolon, log = TRUE)
}
```

# setting up the prior 

```{r}
# perturbs observations with probability epsilon
noisy_observation <- function(y, n = 1, epsilon = .2) {
  ys <- rep(y, n)
  noisy <- rbernoulli(p = epsilon, n = n)
  return(ifelse(noisy, 1-ys, ys))
}

n_samps <- 100 # this is technically j? 

alpha_theta <- 1
beta_theta <- 1

alpha_epsilon <- 1
beta_epsilon <- 10

theta <- .3
epsilon <- .2


# our training data n observations of individual exemplars of this concept y


# y1 = [rbernoulli(p = theta_y1_f1, n = 1), rbernoulli(p = theta_y1_f2, n = 1), rbernoulli(p = theta_y1_f3, n = 1)]


# concept z 
#[rbernoulli(p = theta_z1_f1, n = 1), rbernoulli(p = theta_z1_f2, n = 1), rbernoulli(p = theta_z1_f3, n = 1)]

y_1 = rbernoulli(p = theta, n = 1) #[f_1]
y_2 = rbernoulli(p = theta, n = 1)
y_3 = rbernoulli(p = theta, n = 1)

# noisy_observation(y = 1, n = 10, epsilon = .2)

z_bar = c(noisy_observation(y = y_1, n = n_samps, epsilon = epsilon),
          noisy_observation(y = y_2, n = n_samps, epsilon = epsilon),
          noisy_observation(y = y_3, n = n_samps, epsilon = epsilon))
```

```{r}
lp_theta_given_z(z_bar, .3, epsilon, alpha_theta, beta_theta, alpha_epsilon, beta_epsilon)
lp_theta_given_z(z_bar, .7, epsilon, alpha_theta, beta_theta, alpha_epsilon, beta_epsilon)
```




# grid posterior 

```{r}
grid_theta <- seq(0.01, .99, 0.01)

unnormalized_log_posterior <- sapply(grid_theta, 
                                 function(x){ 
                                   lp_theta_given_z(z_bar = z_bar, 
                                                    theta = x, 
                                                    epsilon = epsilon, 
                                                    alpha_theta = alpha_theta, 
                                                    beta_theta = beta_theta,
                                                    alpha_epsilon = alpha_epsilon, 
                                                    beta_epsilon = beta_epsilon)})

plot(grid_theta, unnormalized_log_posterior)

```




```{r}
grid_theta <- seq(0.01, .99, .01)
grid_epsilon <- seq(0.01, .99, .01)

samps <- expand_grid(theta = grid_theta,
                     epsilon = grid_epsilon) 
  

samps$unnormalized_log_posterior <- mapply(function(x, y) 
                                   lp_theta_given_z(z_bar = z_bar, 
                                                    theta = x, 
                                                    epsilon = y, 
                                                    alpha_theta = alpha_theta, 
                                                    beta_theta = beta_theta,
                                                    alpha_epsilon = alpha_epsilon, 
                                                    beta_epsilon = beta_epsilon), 
                                   samps$theta, 
                                   samps$epsilon)

# normalizing 

samps$log_posterior = samps$unnormalized_log_posterior - matrixStats::logSumExp(samps$unnormalized_log_posterior)

ggplot(samps, 
       aes(x = theta, y = log_posterior, col = epsilon, group = epsilon)) +
  geom_line() + 
  viridis::scale_color_viridis()

```


```{r}
theta_posterior <- samps %>%
  group_by(theta) %>%
  summarise(log_posterior = matrixStats::logSumExp(log_posterior) + 
              log(1/length(log_posterior))) %>%
  mutate(posterior = exp(log_posterior))

ggplot(theta_posterior, 
       aes(x = theta, y = posterior)) +
  geom_line() + 
  viridis::scale_color_viridis() +
  ylim(0,.01)
  
```



```{r}
new_prior <- theta_posterior
new_prior

# recompute p(\theta | z)

new_z <- c(noisy_observation(y = y_1, n = 1000, epsilon = epsilon),
          noisy_observation(y = y_2, n = 1000, epsilon = epsilon),
          noisy_observation(y = y_3, n = 1000, epsilon = epsilon))


grid_theta <- seq(0.01, .99, 0.01)

update_lp_theta <- function(theta_value, updated_posterior){
  
  updated_posterior %>% 
    filter(theta == theta_value) %>% 
    select(log_posterior) %>% 
    pull()
  
}



update_lp_theta_given_z_after_observation <- function(new_observation, 
                                                      theta, 
                                                      epsilon, 
                                                      updated_posterior, 
                                                      alpha_epsilon, 
                                                      beta_epsilon){
  
  
    #sampling from the updated posterior, which is a broken beta distribution 
  
    new_lp_theta <- update_lp_theta(theta, updated_posterior)
    new_lp_epsilon <- lp_episolon(epsilon, alpha_epsilon, beta_epsilon)  
    new_lp_z_given_theta <- lp_z_given_theta(new_observation, theta, epsilon)
    print(new_lp_theta)
    print(new_lp_epsilon)
    print(new_lp_z_given_theta)
    
    return (new_lp_theta + new_lp_epsilon + new_lp_z_given_theta)
  
  
  
  }


new_unormalized_log_posterior <- sapply(grid_theta, 
                                 function(x){ 
                                   update_lp_theta_given_z_after_observation(new_observation = new_z, 
                                                    theta = x, 
                                                    epsilon = epsilon, 
                                                    updated_posterior = new_prior,
                                                    alpha_epsilon = alpha_epsilon, 
                                                    beta_epsilon = beta_epsilon)})


theta_posterior$new_udpated_posterior <- new_unormalized_log_posterior
# p / sum(p)
theta_posterior$new_normalized_posterior <- new_unormalized_log_posterior - matrixStats::logSumExp(new_unormalized_log_posterior)

theta_posterior$normalized_old_posterior <- theta_posterior$posterior/(sum(theta_posterior$posterior))

ggplot(theta_posterior) +
  geom_point(aes(x = theta, y = (normalized_old_posterior), alpha = .3)) + 
 geom_point(aes(x = theta, y = exp(new_normalized_posterior)))

```






# generative stuff for multiple features 
```{r}
feature_noisy_observation <- function(y, n, epsilon){
  ys <- rep(y, n)
  noisy <- rbernoulli(p = epsilon, n = n)
  return(ifelse(noisy, 1-ys, ys))
}

creature_noisy_observation <- function(creature, n, epsilon){
  sapply(creature, function(y){feature_noisy_observation(
    y = y, 
    n = n, 
    epsilon
  )})
}

creature_thetas <- c(0.2, 0.2, 0.8)
  
  

creature <- sapply(creature_thetas, function(x){rbernoulli(p = x, n = 1)})
creature_noisy_z <- creature_noisy_observation(creature, 200, 0.2)

creature
creature_noisy_z
```

```{r}
grid_estimate_theta_only <- function(feature_index, 
                                     thetas, 
                                     z_bar, 
                                     epsilon, 
                                     alpha_theta, 
                                     beta_theta,
                                     alpha_epsilon, 
                                     beta_epsilon){
  
  posterior_df <- tibble("grid_theta" = thetas)
  posterior_df$unnormalized_log_posterior <- sapply(thetas, 
                                 function(x){ 
                                   lp_theta_given_z(z_bar = z_bar, 
                                                    theta = x, 
                                                    epsilon = epsilon, 
                                                    alpha_theta = alpha_theta, 
                                                    beta_theta = beta_theta,
                                                    alpha_epsilon = alpha_epsilon, 
                                                    beta_epsilon = beta_epsilon)})
  posterior_df$normalized_log_posterior <- posterior_df$unnormalized_log_posterior - matrixStats::logSumExp(posterior_df$unnormalized_log_posterior)
  posterior_df$feature_index <- feature_index
  
  return(posterior_df)
  
}

grid_estimate_theta_only(1,
                         seq(0.01, 0.99, 0.01), 
                         creature_noisy_z[,2], 
                         epsilon, 
                                     alpha_theta, 
                                     beta_theta,
                                     alpha_epsilon, 
                                     beta_epsilon)

```

````{r}
grid_estimate_creature_posterior <- function(creature_noisy_z, 
                                        thetas, 
                                        epsilon, 
                                        alpha_theta, 
                                        beta_theta, 
                                        alpha_epsilon, 
                                        beta_epsilon){
  
  
    feature_number = ncol(creature_noisy_z)
    
    lapply(seq(1, feature_number, 1), 
           function(x){
             grid_estimate_theta_only(
               feature_index = x, 
                thetas = thetas, 
                z_bar = creature_noisy_z[,x], 
                epsilon = epsilon , 
                alpha_theta = alpha_theta, 
                beta_theta = beta_theta,
                alpha_epsilon = alpha_epsilon, 
                beta_epsilon = beta_epsilon
             )
           }
           ) %>% 
      bind_rows()
    
  
  
  
}

grid_estimate_creature_posterior(creature_noisy_z, 
                                        seq(0.01, 0.99, 0.01), 
                                        epsilon, 
                                        alpha_theta, 
                                        beta_theta, 
                                        alpha_epsilon, 
                                        beta_epsilon)
```

# now also adding grid approximate over the episolon? 
```{r}
grid_estimate_creature_posterior_with_epsilon <- function(
                                        creature_noisy_z, 
                                        thetas, 
                                        epsilons, 
                                        alpha_theta, 
                                        beta_theta, 
                                        alpha_epsilon, 
                                        beta_epsilon){
  
  
  
  
  

  }
```


# ok do some calculation 
- surprise
- KL divergence: https://machinelearningmastery.com/divergence-between-probability-distributions/#:~:text=KL%20divergence%20can%20be%20calculated,of%20the%20event%20in%20P.&text=The%20value%20within%20the%20sum%20is%20the%20divergence%20for%20a%20given%20event.







