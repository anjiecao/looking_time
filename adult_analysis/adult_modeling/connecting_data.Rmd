---
title: "connecting_data_model"
author: "anjie"
date: "4/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(tidyverse)
```

# process the original data 
```{r}
d <- read_csv(here("adult_modeling/data/processed_RTdata.csv"))


```
## recover the block sequence 
```{r}

d_block_length <- d %>% 
  mutate(temp_id = paste(subject, block_number)) %>% 
  group_by(temp_id) %>% 
  count() %>% 
  rename(block_length = n)

d_experiment_parameter <- d %>% 
  rowwise() %>% 
  mutate(
    temp_id = paste(subject, block_number), 
    dev_positions = case_when(
    !is.na(first_dev_position) && !is.na(second_dev_position) ~ map2(first_dev_position, second_dev_position, c), 
    is.na(first_dev_position) && !is.na(second_dev_position) ~ list(second_dev_position), 
    !is.na(first_dev_position) && is.na(second_dev_position) ~ list(first_dev_position),
    TRUE ~ list(NA)
    )) %>% 
  left_join(d_block_length, by = "temp_id") %>% 
  select(-temp_id) %>% 
  separate(block_type, into = c("complexity", "similarity"), sep = "_") %>% 
  select(subject, block_number, complexity, similarity, block_length, dev_positions) %>% 
  distinct(subject, block_number, .keep_all = TRUE)
  

d_experiment_parameter
```

recover the experiment sequence 
```{r}
d_exp_sim <- d_experiment_parameter %>% 
  # the block length doesn't match 
  mutate(
    
    sequence = pmap(d_experiment_parameter %>% select(-c(subject, block_number)), .f = ~with(list(...), 
                                             get_block_sequence(complexity, similarity, 
                                                                20, 
                                                                5, 10, 
                                                                0.2, 0.8, 
                                                                block_length, 
                                                                dev_positions)))
  ) %>% 
   mutate(beta = map(.x = sequence, 
                    .f = get_beta_count), 
         probability = map(.x = beta, 
                           .f = get_probability), 
         surprise = map2(.x = probability, 
                         .y = sequence, 
                         .f = get_surprise), 
         learning_progress = map(
           .x = probability, 
           .f = get_learning_progress
         )) %>% 
  unnest(sequence, surprise, learning_progress) %>%
  unnest(learning_progress) %>% 
  # figure out the corresponding trial number 
  group_by(subject, block_number) %>% 
  mutate(trial_number = row_number()) 
```




```{r}
d_rt <- d %>% 
  select(subject, block_number, trial_number, rt, item_type, trial_type, trial_complexity) %>% 
  mutate(rt = rt + 500) %>%  # add the baseline back 
  mutate(temp_id = paste(subject, block_number, trial_number)) %>% 
  #rename(real_trial_number = trial_number) %>% 
  select(temp_id, rt, item_type, trial_type, trial_complexity)

d_exp_sim <- d_exp_sim %>% 
  mutate(temp_id = paste(subject, block_number, trial_number)) %>% 
  left_join(d_rt, by = "temp_id") 


```

now d_exp_sim has all the relevant info, let's plot them 
```{r}
ggplot(d_exp_sim, 
       aes(x= trial_number, y=learning_progress, colour=item_type)) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  geom_smooth(method = "lm", 
              formula = y ~ I(exp(1)**(-x)), se = FALSE) + 
  facet_wrap(~trial_complexity) +
  langcog::scale_color_solarized(name = "Item Type") + 
  theme(legend.position = "bottom") + 
  ylab("surprise") + 
  xlab("Trial Number") 

ggplot(d_exp_sim, 
       aes(x= trial_number, y=surprise, colour=item_type)) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  geom_smooth(method = "lm", 
              formula = y ~ I(exp(1)**(-x)), se = FALSE) + 
  facet_wrap(~trial_complexity) +
  langcog::scale_color_solarized(name = "Item Type") + 
  theme(legend.position = "bottom") + 
  ylab("surprise") + 
  xlab("Trial Number") 

# just double check if the plot is right 

ggplot(d %>% mutate(rt = 500 +as.numeric(rt)), 
       aes(x=trial_number, y=log(rt), colour=item_type)) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  geom_smooth(method = "lm", 
              formula = y ~ I(exp(1)**(-x)), se = FALSE) + 
  facet_wrap(~trial_complexity) +
  langcog::scale_color_solarized(name = "Item Type") + 
  theme(legend.position = "bottom") + 
  ylab("rt") + 
  xlab("Trial Number") 

# oh well, what i thought was a bug was not a bug after all. adding 500 did change the plot a little bit. rip my morning. 
```

```{r}
d_exp_sim %>% 
  pivot_longer(cols = c(surprise, learning_progress, rt), 
               names_to = "measure_type", 
               values_to = "measure_value") %>% 
  filter(measure_type == "surprise") %>% 
  ggplot(
       aes(x=trial_number, y=measure_value, colour=item_type)) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  geom_smooth(method = "lm", 
              formula = y ~ I(exp(1)**(-x)), se = FALSE) + 
  facet_grid(~trial_complexity) +
  langcog::scale_color_solarized(name = "Item Type") + 
  theme(legend.position = "bottom") + 
  ylab("surprise") + 
  xlab("Trial Number") 


d_exp_sim %>% 
  pivot_longer(cols = c(surprise, learning_progress, rt), 
               names_to = "measure_type", 
               values_to = "measure_value") %>% 
  filter(measure_type == "learning_progress") %>% 
  ggplot(
       aes(x=trial_number, y=measure_value, colour=item_type)) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  geom_smooth(method = "lm", 
              formula = y ~ I(exp(1)**(-x)), se = FALSE) + 
  facet_grid(~trial_complexity) +
  langcog::scale_color_solarized(name = "Item Type") + 
  theme(legend.position = "bottom") + 
  ylab("learning_progress") + 
  xlab("Trial Number") 


d_exp_sim %>% 
  pivot_longer(cols = c(surprise, learning_progress, rt), 
               names_to = "measure_type", 
               values_to = "measure_value") %>% 
  filter(measure_type == "rt") %>% 
  ggplot(
       aes(x=trial_number, y=log(measure_value), colour=item_type)) + 
  stat_summary(fun.data = "mean_cl_boot", position = position_dodge(width = .2)) + 
  geom_smooth(method = "lm", 
              formula = y ~ I(exp(1)**(-x)), se = FALSE) + 
  facet_grid(~trial_complexity) +
  langcog::scale_color_solarized(name = "Item Type") + 
  theme(legend.position = "bottom") + 
  ylab("rt") + 
  xlab("Trial Number") 
  
```

```{r}
d_exp_sim %>% 
  filter(is.na(dev_positions)) %>% 
  filter(trial_type == "background") %>% 
  ggplot(aes(x = trial_number, y = learning_progress, color = trial_complexity)) +
  geom_point() + 
  geom_line()
  
```



# explore correlation 

```{r}
d_cor <- d_exp_sim %>% 
  select(subject, block_number, trial_number, 
         trial_type, trial_complexity, item_type,
         surprise, learning_progress, rt) %>% 
  mutate(log_rt = log(rt))
```

## surprise and rt 
```{r}

d_cor %>% 
  ggplot(aes(x = surprise, y = log(rt))) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()
  
d_cor %>% 
  ggplot(aes(x = surprise, y = log(rt), color = trial_number)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()

d_cor %>% 
  ggplot(aes(x = surprise, y = log(rt), color = trial_complexity)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()

d_cor %>% 
  ggplot(aes(x = surprise, y = log(rt), color = item_type)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()
```

## learning progress and rt 
```{r}

d_cor %>% 
  ggplot(aes(x = learning_progress, y = log(rt))) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()
  
d_cor %>% 
  ggplot(aes(x = learning_progress, y = log(rt), color = trial_number)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()

d_cor %>% 
  ggplot(aes(x = learning_progress, y = log(rt), color = trial_complexity)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()

d_cor %>% 
  ggplot(aes(x = learning_progress, y = log(rt), color = item_type)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()
```

## omg why is it so flat learning progress and surprise? 
```{r}
d_cor %>% 
  ggplot(aes(x = learning_progress, y = surprise)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()
  
d_cor %>% 
  ggplot(aes(x = learning_progress, y = surprise, color = trial_number)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()

d_cor %>% 
  ggplot(aes(x = learning_progress, y = surprise, color = trial_complexity)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()

d_cor %>% 
  ggplot(aes(x = learning_progress, y = surprise, color = item_type)) + 
  geom_jitter(height = .1, alpha = .1) + 
  geom_smooth()

d_cor
```


# Calculate RMSE and Pearson 
```{r}
library(Metrics)
rmse(d_cor$log_rt, d_cor$learning_progress)
cor(x = d_cor$log_rt, y = d_cor$learning_progress, method = "pearson")
rmse(d_cor$log_rt, d_cor$surprise)
cor(x = d_cor$log_rt, y = d_cor$surprise, method = "pearson")
```

## now try a bunch of parameters 

```{r}
#technically we only need one sequence if we want to vary prior
generate_sequence <- function(d,
                               d_rt, 
                               total_feature_n, 
                               complex_feature_n, 
                               simple_feature_n, 
                               similar_ratio, 
                               dissimilar_ratio, 
                               prior){
 
  d_exp_sim <- d %>% 
  # the block length doesn't match 
  mutate(
    
    sequence = pmap(d_experiment_parameter %>% select(-c(subject, block_number)), .f = ~with(list(...), 
                                             get_block_sequence(complexity, similarity, 
                                                                total_feature_n, 
                                                                simple_feature_n, 
                                                                complex_feature_n, 
                                                                similar_ratio, 
                                                                dissimilar_ratio, 
                                                                block_length, 
                                                                dev_positions)))
    ) #%>% 
    # unnest(sequence) %>% 
   # group_by(subject, block_number) %>% 
  #mutate(trial_number = row_number())
    
  # this should be added later so less computation load 
  
  # d_rt <- d_rt %>% 
  # select(subject, block_number, trial_number, rt, item_type, trial_type, trial_complexity) %>% 
  # mutate(rt = rt + 500) %>%  # add the baseline back 
  # mutate(temp_id = paste(subject, block_number, trial_number)) %>% 
  # #rename(real_trial_number = trial_number) %>% 
  # select(temp_id, rt, item_type, trial_type, trial_complexity)
  # 
  # d_exp_sim <- d_exp_sim %>% 
  #  mutate(temp_id = paste(subject, block_number, trial_number)) %>% 
  #   left_join(d_rt, by = "temp_id") 
  
  
  
  return(d_exp_sim)
  
  
  
}

df_sequence <- generate_sequence(d_experiment_parameter, 
                           d,
                   200, 
                   100, 
                   50, 
                   0.2, 
                   0.6)


```


```{r}
df_sequence
```



```{r}
calculate_prior <- function(d_sequence,  
                               prior) {
  
  
  get_beta_count <- function(block, feature_prior = prior){
    prior <- replicate(length(block[[1]]), feature_prior, simplify = FALSE)
    
    beta_count <- list()
    beta_count[[1]] <- prior 
    for (trial in 1:length(block)){
      beta_count[[trial+1]] <- mapply(function(x, y) {
           x[y + 1] <- x[y + 1] + 1
           return(list(x))
         },
         beta_count[[trial]], 
         block[[trial]])
    }
  
      return(beta_count)

  }
  
  
  d_measure <- d_sequence %>% 
   mutate(beta = map(.x = sequence, 
                    .f = get_beta_count), 
         probability = map(.x = beta, 
                           .f = get_probability), 
         surprise = map2(.x = probability, 
                         .y = sequence, 
                         .f = get_surprise), 
         learning_progress = map(
           .x = probability, 
           .f = get_learning_progress
         )) %>% 
  unnest(sequence, surprise, learning_progress) %>%
  unnest(learning_progress) #%>% 
  # figure out the corresponding trial number 
  #mutate( 
   #      prior =  lapply(list(prior), function(x) x/sum(x))
  #       ) 

 
  
  
  return(d_measure)
  
  
}

ptm <- proc.time()
df_calculated <- calculate_prior(df_sequence, c(3,1))
proc.time() - ptm
```

```{r}
df_calculated
```

```{r}
combine_rt_df <- function(df_measurement, d_rt){
   d_rt <- d_rt %>% 
  select(subject, block_number, trial_number, rt, item_type, trial_type, trial_complexity) %>% 
   mutate(rt = rt + 500) %>%  # add the baseline back 
   mutate(temp_id = paste(subject, block_number, trial_number)) %>% 
   select(temp_id, rt, item_type, trial_type, trial_complexity)
   
   df_combined <- df_measurement %>% 
     group_by(subject, block_number) %>% 
     mutate(trial_number = row_number()) %>% 
    mutate(temp_id = paste(subject, block_number, trial_number)) %>% 
     left_join(d_rt, by = "temp_id") 
   
   return(df_combined)
  
}

df_combined <- combine_rt_df(df_calculated, d)

```

```{r}
df_combined
```



```{r}

calculate_correlation <- function(df){
  
  d <- df %>% 
    mutate(log_rt = log(rt))
  
  lp_rmse <- rmse(d$log_rt, d$learning_progress)
  s_rmse <- rmse(d$log_rt, d$surprise)
  
  lp_pearson <- cor(x = d$log_rt, y = d$learning_progress, 
                    method = "pearson")
  s_pearson <- cor(x = d$log_rt, y = d$surprise, 
                    method = "pearson")

  d_result <- d %>% 
    ungroup() %>% 
    mutate(
      lp_rmse = lp_rmse, 
      s_rmse = s_rmse, 
      lp_pearson = lp_pearson, 
      s_pearson = s_pearson) %>% 
    distinct(lp_rmse, s_rmse, lp_pearson, s_pearson)
    # ) %>% 
    # pivot_longer(
    #   lp_rmse:s_rmse, 
    #   names_to = "rmse_type", 
    #   values_to = "rmse_value"
    # ) %>% 
    # pivot_longer(
    #   lp_pearson:s_pearson, 
    #   names_to = "pearson_type", 
    #   values_to = "pearson_value"
    # )
  
  return (d_result)
}

calculate_correlation(df_combined)
```

## varying prior? 
```{r}
pos <- as.list(seq(1,5, 1))
neg <- as.list(seq(1, 5, 1))

#pos <- seq(1,10, 1)
#neg <- seq(1, 10, 1)

prior_df <- expand.grid(pos, neg) %>% 
  as.data.frame() %>% 
  unnest(`Var1`, `Var2`) %>% 
  filter(`Var1` > `Var2`)

 
#prior_list <- lapply(apply(prior_df,2 , identity), unlist)

prior_list <- list(c(1, 1), 
                   c(2, 1), 
                   c(3, 1), 
                   c(4, 1), 
                   c(5, 1),
                   c(6, 1),
                   c(3, 2), 
                   c(5, 2))

```

# looping over the prior list and run simulation
```{r}
correlation = list()


for (s in 1:length(prior_list)) {
    prior = prior_list[[s]]
    prior_value = prior[[1]] / (prior[[1]] + prior[[2]])

    sim_data <- calculate_prior(df_sequence, prior)
    combined_rt_df <- combine_rt_df(sim_data, d)
    sim_corrleation <- calculate_correlation(combined_rt_df) %>% 
      mutate(sim_id = s, 
             prior_v = prior_value)
    correlation[[s]] <- sim_corrleation  # add it to your list
}


calculated_correlation = do.call(rbind, correlation)
```

```{r}
calculated_correlation
save(calculated_correlation, file = here("adult_modeling/calculated_correlation.RData"))

```
```{r}
calculated_correlation %>% 
  pivot_lo
```





## a mini version 
```{r}
df_mini_sequence <- generate_sequence(d_experiment_parameter, 
                           d,
                   30, 
                   10, 
                   5, 
                   0.2, 
                   0.6)

correlation = list()


for (s in 1:length(prior_list)) {
    prior = prior_list[[s]]
    prior_value = prior[[1]] / (prior[[1]] + prior[[2]])

    sim_data <- calculate_prior(df_mini_sequence, prior)
    combined_rt_df <- combine_rt_df(sim_data, d)
    sim_corrleation <- calculate_correlation(combined_rt_df) %>% 
      mutate(sim_id = s, 
             prior_v = prior_value)
    correlation[[s]] <- sim_corrleation  # add it to your list
}


calculated_correlation = do.call(rbind, correlation)
```

```{r}
calculated_correlation %>% 
  pivot_longer(lp_rmse:s_pearson, names_to = "measure_type", 
               values_to = "correlation_value") %>% 
  separate(measure_type, into = c("learning_measure_type", "correlation_measure_type")) %>% 
  filter(correlation_measure_type == "rmse") %>% 
  ggplot(aes(x = prior_v, 
             y = correlation_value, 
             color = learning_measure_type)) + 
  geom_point() + 
  geom_line() + 
  ylab("rmse")

calculated_correlation %>% 
  pivot_longer(lp_rmse:s_pearson, names_to = "measure_type", 
               values_to = "correlation_value") %>% 
  separate(measure_type, into = c("learning_measure_type", "correlation_measure_type")) %>% 
  filter(correlation_measure_type == "pearson") %>% 
  ggplot(aes(x = prior_v, 
             y = correlation_value, 
             color = learning_measure_type)) + 
  geom_point() + 
  geom_line() + 
  ylab("pearson")
```

## trying different similar / dissimilar ratio 
```{r}
similarity_list = list(c(0.1, 0.3 ), 
                       c(0.1, 0.4 ), 
                       c(0.1, 0.5 ), 
                       c(0.1, 0.6 ), 
                       c(0.1, 0.7 ), 
                       c(0.2, 0.3 ), 
                       c(0.2, 0.4 ), 
                       c(0.2, 0.5 ), 
                       c(0.2, 0.6 ), 
                       c(0.2, 0.7 ))


correlation = list()


for (s in 1:length(similarity_list)) {
  
    df_mini_sequence <- generate_sequence(d_experiment_parameter, 
                           d,
                   30, 
                   10, 
                   5, 
                   similarity_list[[s]][1], 
                    similarity_list[[s]][2])

    
    prior = c(3, 1)

    sim_data <- calculate_prior(df_mini_sequence, c(3, 1))
    combined_rt_df <- combine_rt_df(sim_data, d)
    sim_corrleation <- calculate_correlation(combined_rt_df) %>% 
      mutate(sim_id = s, 
             prior_v = prior_value)
    correlation[[s]] <- sim_corrleation  # add it to your list
}


calculated_correlation = do.call(rbind, correlation)
```

```{r}
save(calculated_correlation, file = here("adult_modeling/varying_similarity.RData"))
calculated_correlation$similarity <- as.vector(similarity_list)
df_vis_correlation <- calculated_correlation %>% 
  unnest_wider(similarity) %>% 
  rename(similar_ratio = ...1, 
         dissimilar_ratio = ...2) %>% 
  mutate(sim_diff = dissimilar_ratio - similar_ratio, 
         sim_ratio = dissimilar_ratio / similar_ratio) %>% 
  pivot_longer(lp_rmse:s_pearson, names_to = "measure_type", 
               values_to = "correlation_value") %>% 
  pivot_longer(sim_diff : sim_ratio, 
               names_to = "similarity_measure", 
               values_to = "similarity_value") %>% 
  separate(measure_type, into = c("learning_measure_type", "correlation_measure_type")) 


  
  
```

```{r}
df_vis_correlation %>% 
filter(correlation_measure_type == "pearson") %>% 
  ggplot(aes(x = dissimilar_ratio, 
             y = correlation_value, 
             color = learning_measure_type)) + 
  geom_point() + 
  geom_line() + 
  ylab("pearson") + 
  facet_wrap(~similar_ratio)
```

